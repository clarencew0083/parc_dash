{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e614fb7",
   "metadata": {},
   "source": [
    "# Project Check In 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bb1eae",
   "metadata": {},
   "source": [
    "## Progress report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f80726",
   "metadata": {},
   "source": [
    "I have confirmed that the data is available under MIT License [1]. They are stored as npy files. Each file has the shape (timesteps, channels, height, width), where the number of channels is five, and the height and width of the image is 128 x 256 pixels. The figure, Interactive Visualization Mock-up, is an example of the interactive plot that will be placed on the dashboard. The parc_dash class will contain methods to connect to the database and to create the visualizations used in the app.py file. The dashboard within the app.py file will have a dropdown for selecting the name of the npy file. After making a selection, the visualizations will dynamically update.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0eae4",
   "metadata": {},
   "source": [
    "### Interactive Visualization Mock up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8188aef8",
   "metadata": {},
   "source": [
    "![title](images/pressure_demo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47015f9c",
   "metadata": {},
   "source": [
    "Data wrangling involved looping through each array channel and storing the timestep, height, and width in a dataframe. The dataframe is then converted to JSON for reading into the database. An example of the dataframe after data wrangling is given below."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ff58a54",
   "metadata": {},
   "source": [
    "timestep\tx\ty\tvalue\n",
    "0\t0\t0\t0\t3.942014e+08\n",
    "1\t0\t0\t1\t-1.200000e-05\n",
    "2\t0\t0\t2\t-1.200000e-05\n",
    "3\t0\t0\t3\t-1.200000e-05\n",
    "4\t0\t0\t4\t-1.200000e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ab8ee",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Each dataframe will have on the order of five hundred thousand rows. This estimate is obtained by using 15 as an example number of timestep and multiplying timesteps, height and width. \n",
    "\n",
    "In the dataframe  $x \\in [0,128]$, $y \\in [0,256]$,  timestep $ \\in \\mathbb{Z}^{+} \\cup {0}$ and value $ \\in \\mathbb{R}$. The infomation stored in the value column will change based on the channel used to generate the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911cd86",
   "metadata": {},
   "source": [
    "## Data summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654062d8",
   "metadata": {},
   "source": [
    "Initially, InfluxDB was chosen as the backend database. The parameters necessary to make a connection to the database are as follows:\n",
    "\n",
    "influx_password = os.getenv('DOCKER_INFLUXDB_INIT_PASSWORD') <br>\n",
    "influx_user= os.getenv('DOCKER_INFLUXDB_INIT_USERNAME') <br>\n",
    "influx_token= os.getenv('DOCKER_INFLUXDB_INIT_TOKEN') <br>\n",
    "influx_org= os.getenv('DOCKER_INFLUXDB_INIT_ORG') <br>\n",
    "influx_bucket= os.getenv('DOCKER_INFLUXDB_INIT_BUCKET') <br>\n",
    "\n",
    "client = influxdb_client.InfluxDBClient(url=\"http://localhost:8086\", username=influx_user, password=influx_password, token=influx_token, org=influx_org) <br><br>\n",
    "I am currenttly having an issue with writing my data to the influxdb. The write example below from the influx documentation works, but when I adapt it to my data, nothing gets writen in the measurement bucket.\n",
    "\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS) <br>\n",
    "\n",
    "p = influxdb_client.Point(\"my_measurement\").tag(\"location\", \"Prague\").field(\"temperature\", 25.3)<br>\n",
    "write_api.write(bucket=influx_bucket, org=influx_org, record=p)<br><br>\n",
    "\n",
    "Due to this issue, MongoDB will store the data. As stated in the previous section, each npy file has been converted to a dataframe to enable the creation of the dashboard's data visualizations. This data frame is then converted to JSON and subsequently read into the MongoDB. Five JSON files, one for each channel, are created for one simulation file. The structure of the JSON is as follows:\n",
    "\n",
    "{ <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;\"variable\": \"pressure\",  <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;\"file\": \"void_100\",  <br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;\"Data\": [  <br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\"timestep\": 0, \"x\": 0, \"y\": 0, \"value\": 100.0},  <br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\"timestep\": 0, \"x\": 0, \"y\": 1, \"value\": 200.0},  <br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{\"timestep\": 0, \"x\": 0, \"y\": 2, \"value\": 300.0}  <br>\n",
    "  ]} <br>\n",
    "\n",
    "In the example JSON, variables can be temperature, pressure, microstructure, velocity (x) or velocity (y). The file key is the name of the npy file. The data key contains the information within the npy file. <br><br>\n",
    "After successfuly creating the dashboard using the mongo database, experimentation with the influx database will continue as time allows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e40f0e",
   "metadata": {},
   "source": [
    "# Database documentation and visualizations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc64d5c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Since Mongo is a NoSql database, there are no relationships to document in the ERD. However, an example diagram of the MongoDB representation of each JSON file is available at https://dbdocs.io/clarencew0083/parc_dash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1179a36a",
   "metadata": {},
   "source": [
    " Each simulation lasts for 15 to 40 nanoseconds. The temperature is measured in degrees kelvin and is valued in the range $[300, 5000]$. Velocity is measured in micrometers per nanosecond. Pressure is measured on gigapascals, and microstructure is expressed as in the range $[0,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5636bfe-7f88-4219-b68b-d40e54a3de22",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3168da-2d7b-4a13-950d-1ee8dfb1c960",
   "metadata": {},
   "source": [
    "[1] Visual Intelligence Laboratory. (2024). PARCv2: Physics-aware Recurrent Convolutional Neural Networks for Spatiotemporal Dynamics Modeling [Data set]. Zenodo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63319cf2-3dbd-480b-99c3-4f2fe57766cc",
   "metadata": {},
   "source": [
    "## Gen AI Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c581ac-4ae1-448e-914f-270a7b74dada",
   "metadata": {},
   "source": [
    "I used generative AI to assist with data wrangling and converting existing visualizations to plotly. Additionally, I used the spell check and editor feature of Grammarly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
