{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7158a7-a65f-4769-9df0-b0741c1594a6",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c5814-d496-48fe-9d83-333f539395c1",
   "metadata": {},
   "source": [
    "Why repeat analysis? When new members join a team or when members depart organizations, valuable information also leaves the organization due to jupyter Notebooks, word documents, or PDFs containing critical analysis existing on the departing members’ desktop. This issue of knowledge management causes many person-hours to be wasted. However, modern solutions allow analysis to persist beyond members' time at an organization. This project places this issue in the context of physics-aware machine learning of highly energetic material. It explicitly addresses data storage related to direct numerical simulations of a shock traveling through porous explosive material with a single void in its construction. When the shock occurs, chemical reactions cause the void to collapse and a denotation to occur, modeled using neural networks instead of direct numerical simulations. \n",
    "\n",
    "The specific goal of this project is to ingest the simulation dataset to present an analysis of how the state of the system changes over time before any machine learning. After reading the dataset, a dashboard will display the distribution of the fields of interest, elementary statistics (mean, median standard deviation) of the variables of interest, and more advanced analysis like a spatial gradient and an animation of the simulation. The current analysis of this dataset resides in a jupyter notebook with handpicked visualizations of a subset of the simulation data. The main contribution of this project is creating the free and open source implementation of an influx database for scientific machine learning concerning physics-informed machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fedbd9-5928-4f89-b1b2-0c2e7fd42b9f",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f775617-7562-4a7f-a9f6-d58d14db096b",
   "metadata": {},
   "source": [
    "### Physics Aware Recurrent Convolutional Neural Networks version 2\n",
    "This research uses Physics Aware Recurrent Convolutional Neural Networks version 2 (PARCv2) [1] to predict how the energetic material changes over time once a sock is applied to the system. This process can be described formally as an advection-diffusion-reaction system and is modeled using a partial differential equation (PDE) given below. \n",
    "$$ \\frac{\\partial \\textbf{x}}{\\partial t} = k  \\nabla \\textbf{x} - \\textbf{u} \\cdot \\Delta + \\textbf{R}_{\\textbf{x}}(\\textbf{x},\\textbf{u},\\textbf{c})$$\n",
    "\n",
    "\n",
    "With initial conditions,\n",
    "\n",
    "$$ \\textbf{u}(t=0) = \\textbf{u}_{0} $$\n",
    "$$ \\textbf{x}(t=0) = \\textbf{x}_{0} $$\n",
    "\n",
    "\n",
    "In the above PDE, $\\textbf{x}$ is the variable of interest: temperature, pressure, or microstructure at a position and time $ t$. $ k $ is the diffusivity coefficient. $ \\textbf{u} $ is the velocity field and is typically decomposed to $ \\textbf{u}_x $ and $\\textbf{u}_y$ to represent the velocity in the $x$ and $y$ direction, respectively.   If $ \\textbf{R}_{\\textbf{x}} $  is equal to zero, then it is known as Burgers’ equation. Essentially, PARCv2 is trying to learn the next state of the system, which can be solved numerically.[1]\n",
    "\n",
    "### Influx\n",
    "InfluxData Inc created InfluxDB is a NoSQL database focused on storing and visualizing time series data. It stores time series data in a parquet format and has an official docker image at https://hub.docker.com/_/influxdb. The utility it provides is the ability to query time series data quickly. [2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d54e6-5782-4e7f-bb6d-617c76f7d79d",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3843735-ea17-49b6-92e4-973a9c0ac7db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The primary data source is 200 direct numerical simulations (DNS) of highly energic material receiving a shock over time. Each file contains velocity, temperature, and pressure fields at a $(x,y)$ position in space over time. Each simulation is a npy file representing a 64 by 128-pixel image with each $(x,y)$ pixel representing the location and containing temperature, pressure, and microstructure values at time $t$ of energetic material.\n",
    "\n",
    "Each simulation lasts for 20 to 40 nanoseconds. The temperature is measured in degrees kelvin and is valued in the range $[300, 5000]$. Velocity is measured in micrometers per nanosecond. Pressure is measured on gigapascals, and microstructure is expressed as in the range $[0,1]$. Each file is hosted in the Visual Intelligence Laboratory project folder on the University of Virginia High-Performance Computing HPC System, and in total, there are 30 GB of files.\n",
    "\n",
    "I will ask the team responsible for creating the 200 DNS for the specific license for usage of the data. A fallback is using data at https://github.com/pdebench/PDEBench, an open-source repository of scientific machine-learning datasets. There is data for Burger's equation mentioned in the background, but it is a 93 GB file.[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d6296-8a70-4156-91cb-f2a93eef7f4b",
   "metadata": {},
   "source": [
    "## Potential Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c147fbf3-f287-4ed1-b893-f2b6e469f150",
   "metadata": {},
   "source": [
    "In data science, one should understand the problem before making an inference. Therefore, the project aims to produce a dashboard to present exploratory analysis of the simulation data before feeding the data to the neural network within PARCv2. The project will focus on ingesting the npy files post-initial processing into a time series database and automatically updating a dashboard with key visualizations to enable the exploratory data analysis of the simulation data. The dashboard will have a dropdown list to select a particular simulation and then show the elementary statistics and the distribution of the variables of interest. Additionally, the dashboard will allow the user to see the simulation play over time. This is shown in the GIF below. The images shown is the temperature, pressure, microstructure, velocity in the x and velocity and the y direction changing over time once a shock is applied to the energiectic material.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5153b48-53ee-4c13-9633-0b0bebb3aecb",
   "metadata": {},
   "source": [
    "![title](images/00_002.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db840f00-55d1-4230-b005-d1e8b5ebe77e",
   "metadata": {},
   "source": [
    "The figure below shows an example histogram of the pressure data for every value in the pressure field of a 64 x 128 image over 25 timesteps from a simulation. For pressure alone, there are 204,800 values in just one simulation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b72b3-b478-499e-960a-ce5edd54e8a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![title](images/pressure_histogram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfa9049-a2d7-48e3-9ff0-4e5119d65b88",
   "metadata": {},
   "source": [
    "## Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7aa73-7ea0-4dcd-856f-6c6051176d57",
   "metadata": {},
   "source": [
    "The main challenge of this project will be scope. Many of the example visualizations rely on the data having the shape of a tensor. Thus, adapting existing code to a new structure or designing the database queries to get the data in the correct format will be a challenge. Fortunately, there is utility in producing easily repeatable and transparent exploratory data analysis beyond this class project. Therefore, I plan to continue this work well beyond the fall semester. Handling the multi-dimensional arrays stored in the npy files is another challenge. The files must be unpacked and read into the influx db one channel at a time. Another issue is that Influx is a NoSQL database, and I have no experience with this type of backend. The syntax is written in Flux, Influx DB’s scripting and query. The documentation at https://docs.influxdata.com/influxdb/v2/ seems to be robust, but I will judge its quality once I dive in. Finally, the true challenge is reading from the data source outside the HPC environment. There are over 30 GB of files. However, I will only use a few files to develop locally. At a high level, the steps to success for this project are defining a database schema for the influx tables, writing the npy file to the influx database, querying the influx database to populate visualizations, and adapting existing visualizations to this new structure. Reading some of the influx documentation reveals that the npy files will potentially have to be converted to CSV’s to facilitate populating the database, which would also be challenging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5636bfe-7f88-4219-b68b-d40e54a3de22",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3168da-2d7b-4a13-950d-1ee8dfb1c960",
   "metadata": {},
   "source": [
    "\n",
    "[1]Nguyen, et al., “PARCv2: Physics-aware Recurrent Convolutional Neural Networks for Spatiotemporal Dynamics Modeling,” arXiv (Cornell University), Feb. 2024, doi: https://doi.org/10.48550/arxiv.2402.12503.\n",
    "‌\n",
    "\n",
    "[2]“InfluxDB | Real-time insights at any scale | InfluxData,” InfluxData, Sep. 23, 2024. https://www.influxdata.com/homepage/ (accessed Oct. 08, 2024).\n",
    "\n",
    "‌\n",
    "[3] Takamoto, Makoto; Praditia, Timothy; Leiteritz, Raphael; MacKinlay, Dan; Alesiani, Francesco; Pflüger, Dirk; Niepert, Mathias, 2022, \"PDEBench Datasets\", https://doi.org/10.18419/darus-2986, DaRUS, V8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63319cf2-3dbd-480b-99c3-4f2fe57766cc",
   "metadata": {},
   "source": [
    "## Gen AI Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c581ac-4ae1-448e-914f-270a7b74dada",
   "metadata": {},
   "source": [
    "I did not use generative AI for this proposal. However, I did use the spell check and editor feature of Grammarly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
